# Chapter 05: Runnable æ¥å£ä¸ä»»åŠ¡ç¼–æ’ç³»ç»Ÿ ğŸ”§

> æŒæ¡ LangChain.js çš„ Runnable æŠ½è±¡ï¼Œæ„å»ºå¯ç»„åˆã€å¯å¤ç”¨ã€å¯æµ‹è¯•çš„æ™ºèƒ½å·¥ä½œæµ

## ğŸ“š ç›®å½•

- [ä»€ä¹ˆæ˜¯ Runnableï¼Ÿ](#ä»€ä¹ˆæ˜¯-runnable)
- [ä¸ºä»€ä¹ˆéœ€è¦ Runnableï¼Ÿ](#ä¸ºä»€ä¹ˆéœ€è¦-runnable)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [æ ¸å¿ƒæ¦‚å¿µè¯¦è§£](#æ ¸å¿ƒæ¦‚å¿µè¯¦è§£)
- [ä»£ç ç¤ºä¾‹è¯¦è§£](#ä»£ç ç¤ºä¾‹è¯¦è§£)
- [å®æˆ˜é¡¹ç›®](#å®æˆ˜é¡¹ç›®)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## ğŸ¯ ä»€ä¹ˆæ˜¯ Runnableï¼Ÿ

### æ ¸å¿ƒç†å¿µ

**Runnable** æ˜¯ LangChain.js çš„**é€šç”¨å¯æ‰§è¡Œå•å…ƒæŠ½è±¡**ã€‚å®ƒç»Ÿä¸€äº†"è¾“å…¥ â†’ å¤„ç† â†’ è¾“å‡º"çš„æ¨¡å¼ï¼Œä½¿å¾— Promptã€Modelã€Parserã€Retrieverã€Tool ç”šè‡³è‡ªå®šä¹‰å‡½æ•°ï¼Œéƒ½èƒ½ä»¥åŒä¸€å¥—æ¥å£è¿›è¡Œç»„åˆä¸ç¼–æ’ã€‚

```typescript
// âŒ æ²¡æœ‰ Runnableï¼šå„ä¸ªç»„ä»¶æ¥å£ä¸ç»Ÿä¸€
const promptResult = formatPrompt(input);
const modelResult = await callModel(promptResult);
const finalResult = parseOutput(modelResult);

// âœ… ä½¿ç”¨ Runnableï¼šç»Ÿä¸€çš„æ¥å£ï¼Œå¯ç»„åˆ
const chain = prompt.pipe(model).pipe(parser);
const result = await chain.invoke(input);
```

### æ ‡å‡†æ¥å£

æ‰€æœ‰ Runnable éƒ½å®ç°äº†ä»¥ä¸‹æ ¸å¿ƒæ–¹æ³•ï¼š

```typescript
interface Runnable<Input, Output> {
  // å•æ¬¡è°ƒç”¨
  invoke(input: Input, options?: RunnableConfig): Promise<Output>;

  // æµå¼äº§å‡º
  stream(input: Input, options?: RunnableConfig): AsyncGenerator<Output>;

  // æ‰¹é‡å¤„ç†
  batch(inputs: Input[], options?: RunnableConfig): Promise<Output[]>;

  // ä¸²è”ä¸‹ä¸€ä¸ª Runnable
  pipe<NewOutput>(next: Runnable<Output, NewOutput>): Runnable<Input, NewOutput>;
}
```

### æ ¸å¿ƒä¼˜åŠ¿

1. **ç»Ÿä¸€æ¥å£**ï¼šæ‰€æœ‰ç»„ä»¶ç”¨åŒæ ·çš„æ–¹å¼è°ƒç”¨
2. **å¯ç»„åˆ**ï¼šé€šè¿‡ `pipe()` è½»æ¾ä¸²è”
3. **å¯å¤ç”¨**ï¼šåŒä¸€ä¸ªç»„ä»¶å¯ç”¨äºä¸åŒåœºæ™¯
4. **å¯æµ‹è¯•**ï¼šæ¯ä¸ªç¯èŠ‚éƒ½å¯ä»¥ç‹¬ç«‹æµ‹è¯•
5. **å¯è§‚æµ‹**ï¼šç»Ÿä¸€çš„ Callback æœºåˆ¶

---

## ğŸ¤” ä¸ºä»€ä¹ˆéœ€è¦ Runnableï¼Ÿ

### 1. è§£å†³æ¥å£ä¸ç»Ÿä¸€çš„é—®é¢˜

**åœºæ™¯**ï¼šæ²¡æœ‰ Runnable æ—¶ï¼Œä¸åŒç»„ä»¶çš„è°ƒç”¨æ–¹å¼å„ä¸ç›¸åŒ

```typescript
// âŒ æ²¡æœ‰ç»Ÿä¸€æ¥å£ï¼šéš¾ä»¥ç»„åˆ
const prompt = formatPrompt(data);
const modelOutput = await model.generate(prompt);
const parsed = parser.parse(modelOutput.text);
const retrieved = await retriever.search(parsed);
```

**ä½¿ç”¨ Runnable**ï¼š

```typescript
// âœ… ç»Ÿä¸€æ¥å£ï¼šè½»æ¾ç»„åˆ
const chain = prompt
  .pipe(model)
  .pipe(parser)
  .pipe(retriever);

const result = await chain.invoke(data);
```

### 2. æå‡ä»£ç å¯å¤ç”¨æ€§

```typescript
// åˆ›å»ºå¯å¤ç”¨çš„ç»„ä»¶
const model = new ChatOpenAI({ temperature: 0 });
const parser = new StringOutputParser();

// åœºæ™¯ 1ï¼šæŠ€æœ¯è§£é‡Š
const explainChain = PromptTemplate
  .fromTemplate("è§£é‡Šï¼š{term}")
  .pipe(model)
  .pipe(parser);

// åœºæ™¯ 2ï¼šä»£ç ç”Ÿæˆ
const codeChain = PromptTemplate
  .fromTemplate("ç”Ÿæˆ {language} ä»£ç ï¼š{task}")
  .pipe(model)
  .pipe(parser);

// åœºæ™¯ 3ï¼šç¿»è¯‘
const translateChain = PromptTemplate
  .fromTemplate("ç¿»è¯‘ï¼š{text}")
  .pipe(model)
  .pipe(parser);

// åŒä¸€ä¸ª Model å’Œ Parserï¼Œæ­é…ä¸åŒ Prompt å®Œæˆä¸åŒä»»åŠ¡
```

### 3. ä¾¿äºæµ‹è¯•å’Œè°ƒè¯•

```typescript
// æ¯ä¸ª Runnable éƒ½å¯ä»¥ç‹¬ç«‹æµ‹è¯•
describe("Prompt Template", () => {
  it("should format correctly", async () => {
    const result = await prompt.invoke({ name: "å¼ ä¸‰" });
    expect(result.toString()).toContain("å¼ ä¸‰");
  });
});

describe("Model", () => {
  it("should generate response", async () => {
    const result = await model.invoke(promptOutput);
    expect(result.content).toBeTruthy();
  });
});

describe("Full Chain", () => {
  it("should work end-to-end", async () => {
    const result = await chain.invoke({ name: "å¼ ä¸‰" });
    expect(typeof result).toBe("string");
  });
});
```

### 4. æ”¯æŒæµå¼å¤„ç†å’Œæ‰¹é‡å¤„ç†

```typescript
// æµå¼å¤„ç†
const stream = await chain.stream(input);
for await (const chunk of stream) {
  process.stdout.write(chunk); // æ‰“å­—æœºæ•ˆæœ
}

// æ‰¹é‡å¤„ç†ï¼ˆæé«˜ååé‡ï¼‰
const results = await chain.batch([input1, input2, input3]);
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# 1. å®‰è£…ä¾èµ–
npm install

# 2. é…ç½® API Key
echo "OPENAI_API_KEY=sk-your-api-key-here" > .env
```

### 2. è¿è¡Œç¬¬ä¸€ä¸ªç¤ºä¾‹

```bash
# è¿è¡ŒåŸºç¡€æµæ°´çº¿ç¤ºä¾‹
npm run runnable:sequence
```

**é¢„æœŸè¾“å‡º**ï¼š

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              æœ€åŸºç¡€çš„ Runnable æµæ°´çº¿                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š æµæ°´çº¿ç»“æ„ï¼š
   Input {role, content}
     â†“
   Prompt Template (æ ¼å¼åŒ–è¾“å…¥)
     â†“
   LLM Model (ç”Ÿæˆå›ç­”)
     â†“
   String Parser (æå–æ–‡æœ¬)
     â†“
   Output (string)

âœ… è¾“å‡ºç»“æœï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. React 18 å¼•å…¥äº†å¹¶å‘ç‰¹æ€§ï¼Œè¿™æ˜¯æ¶æ„çš„é‡å¤§å‡çº§
2. ä¸»è¦åŒ…æ‹¬è‡ªåŠ¨æ‰¹å¤„ç†ã€è¿‡æ¸¡ã€æ‚¬å¿µç­‰åŠŸèƒ½
3. ä½¿ç”¨ useTransition å’Œ useDeferredValue æ ‡è®°éç´§æ€¥æ›´æ–°
4. è®© React èƒ½ä¿æŒå“åº”æ€§ï¼Œå³ä½¿åœ¨å¤§é‡æ›´æ–°æ—¶ä¹Ÿæµç•…
5. ä¼˜å…ˆå¤„ç†ç”¨æˆ·äº¤äº’ï¼Œæ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### 3. è¿è¡Œå…¶ä»–ç¤ºä¾‹

```bash
# æ ¸å¿ƒæ¦‚å¿µ
npm run runnable:lambda          # Lambda å‡½æ•°åŒ…è£…
npm run runnable:parallel        # å¹¶è¡Œæ‰§è¡Œ
npm run runnable:branch          # æ¡ä»¶åˆ†æ”¯
npm run runnable:stream          # æµå¼å¤„ç†
npm run runnable:errors          # é”™è¯¯å¤„ç†

# å®æˆ˜é¡¹ç›®
npm run runnable:content-pipeline # å†…å®¹å¤„ç†æµæ°´çº¿
npm run runnable:rag-etl         # RAG æ•°æ®å¤„ç†
```

---

## ğŸ” æ ¸å¿ƒæ¦‚å¿µè¯¦è§£

### 1. å¸¸ç”¨ Runnable å®ç°

#### RunnableLambda

å°†ä»»æ„å‡½æ•°åŒ…è£…ä¸º Runnableï¼š

```typescript
import { RunnableLambda } from "@langchain/core/runnables";

// åŒæ­¥å‡½æ•°
const uppercase = new RunnableLambda<string, string>((text) => {
  return text.toUpperCase();
});

// å¼‚æ­¥å‡½æ•°
const fetchData = new RunnableLambda<string, any>(async (id) => {
  const response = await fetch(`/api/data/${id}`);
  return response.json();
});

// ä½¿ç”¨
const result = await uppercase.invoke("hello"); // "HELLO"
```

**é€‚ç”¨åœºæ™¯**ï¼š
- æ•°æ®é¢„å¤„ç†ï¼ˆæ¸…æ´—ã€æ ¼å¼åŒ–ã€éªŒè¯ï¼‰
- è‡ªå®šä¹‰é€»è¾‘ï¼ˆè®¡ç®—ã€è½¬æ¢ã€è·¯ç”±ï¼‰
- å¤–éƒ¨ API è°ƒç”¨
- æ•°æ®åº“æ“ä½œ

#### RunnableSequence

æŒ‰é¡ºåºä¸²è”å¤šä¸ª Runnableï¼š

```typescript
import { RunnableSequence } from "@langchain/core/runnables";

// æ–¹å¼ 1ï¼šä½¿ç”¨ pipe()
const chain = step1.pipe(step2).pipe(step3);

// æ–¹å¼ 2ï¼šä½¿ç”¨ from()
const chain = RunnableSequence.from([step1, step2, step3]);

// æ•°æ®æµï¼šInput â†’ step1 â†’ step2 â†’ step3 â†’ Output
```

#### RunnableParallel

å¹¶è¡Œæ‰§è¡Œå¤šä¸ª Runnableï¼š

```typescript
import { RunnableParallel } from "@langchain/core/runnables";

const parallel = new RunnableParallel({
  task1: runnable1,
  task2: runnable2,
  task3: runnable3,
});

const result = await parallel.invoke(input);
// ç»“æœ: { task1: ..., task2: ..., task3: ... }
```

**æ‰§è¡Œæµç¨‹**ï¼š

```
        Input
          â†“
    â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”
    â†“     â†“     â†“
  task1 task2 task3  (å¹¶è¡Œ)
    â†“     â†“     â†“
    â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”˜
          â†“
   { task1, task2, task3 }
```

#### RunnablePassthrough

åŸæ ·é€ä¼ è¾“å…¥ï¼š

```typescript
import { RunnablePassthrough } from "@langchain/core/runnables";

const chain = RunnableSequence.from([
  RunnablePassthrough.assign({
    // ä¿ç•™åŸå§‹è¾“å…¥ï¼Œæ·»åŠ æ–°å­—æ®µ
    processed: processLambda,
  }),
]);

// Input: { text: "hello" }
// Output: { text: "hello", processed: "HELLO" }
```

### 2. æ ¸å¿ƒæ–¹æ³•è¯¦è§£

#### invoke() - å•æ¬¡æ‰§è¡Œ

```typescript
const result = await runnable.invoke(input, {
  callbacks: [handler],  // å›è°ƒ
  tags: ["demo"],        // æ ‡ç­¾
  metadata: { user: "å¼ ä¸‰" }, // å…ƒæ•°æ®
});
```

#### stream() - æµå¼æ‰§è¡Œ

```typescript
const stream = await runnable.stream(input);

for await (const chunk of stream) {
  process.stdout.write(chunk); // å®æ—¶è¾“å‡º
}
```

#### batch() - æ‰¹é‡æ‰§è¡Œ

```typescript
const results = await runnable.batch([
  input1,
  input2,
  input3,
], {
  maxConcurrency: 3, // é™åˆ¶å¹¶å‘æ•°
});
```

#### pipe() - ä¸²è”

```typescript
const chain = runnable1
  .pipe(runnable2)
  .pipe(runnable3);

// ç­‰ä»·äºï¼š
const chain = RunnableSequence.from([
  runnable1,
  runnable2,
  runnable3,
]);
```

### 3. ç¼–æ’æ¨¡å¼

#### é¡ºåºæµæ°´çº¿

```
Input â†’ Step1 â†’ Step2 â†’ Step3 â†’ Output
```

```typescript
const pipeline = step1.pipe(step2).pipe(step3);
```

#### æ¡ä»¶åˆ†æ”¯

```
       Input
         â†“
      [åˆ¤æ–­]
       â†™  â†˜
    è·¯å¾„A  è·¯å¾„B
       â†˜  â†™
       Output
```

```typescript
const router = new RunnableLambda(async (input) => {
  if (condition(input)) {
    return await pathA.invoke(input);
  } else {
    return await pathB.invoke(input);
  }
});
```

#### æ‰‡å‡º/æ±‡èšï¼ˆFan-out/Fan-inï¼‰

```
        Input
          â†“
    â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”
    â†“     â†“     â†“
   R1    R2    R3  (å¹¶è¡Œ)
    â†“     â†“     â†“
    â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”˜
          â†“
       Merge
          â†“
       Output
```

```typescript
const pipeline = RunnableSequence.from([
  new RunnableParallel({ a: r1, b: r2, c: r3 }),
  mergeLambda,
]);
```

#### Map/Reduce

```
   Input (array)
       â†“
    [Map] (å¯¹æ¯ä¸ªå…ƒç´ åº”ç”¨ Runnable)
       â†“
  [Reduce] (æ±‡æ€»ç»“æœ)
       â†“
   Output
```

```typescript
const mapReduce = new RunnableLambda(async (items: string[]) => {
  // Map: å¹¶è¡Œå¤„ç†æ¯ä¸ªå…ƒç´ 
  const mapped = await Promise.all(
    items.map((item) => processLambda.invoke(item))
  );

  // Reduce: æ±‡æ€»ç»“æœ
  return merged.reduce((acc, item) => acc + item, "");
});
```

---

## ğŸ’» ä»£ç ç¤ºä¾‹è¯¦è§£

### æ¡ˆä¾‹ 1ï¼šåŸºç¡€æµæ°´çº¿ï¼ˆSequenceï¼‰

**æ–‡ä»¶**ï¼š[sequence-basic.ts](./sequence-basic.ts)

**åŠŸèƒ½**ï¼šæ¼”ç¤º Prompt â†’ Model â†’ Parser çš„åŸºç¡€æµæ°´çº¿

**æ ¸å¿ƒä»£ç **ï¼š

```typescript
// 1. åˆ›å»ºå„ä¸ª Runnable
const prompt = PromptTemplate.fromTemplate("ä½ æ˜¯{role}ï¼Œæ€»ç»“ï¼š{content}");
const model = new ChatOpenAI({ temperature: 0 });
const parser = new StringOutputParser();

// 2. ä½¿ç”¨ pipe() ä¸²è”
const chain = prompt.pipe(model).pipe(parser);

// 3. è°ƒç”¨
const result = await chain.invoke({
  role: "æŠ€æœ¯ä½œè€…",
  content: "React 18 å¹¶å‘ç‰¹æ€§...",
});
```

**è¿è¡Œç¤ºä¾‹**ï¼š

```bash
npm run runnable:sequence
```

**å­¦ä¹ è¦ç‚¹**ï¼š
- æ‰€æœ‰ç»„ä»¶ï¼ˆPromptã€Modelã€Parserï¼‰éƒ½æ˜¯ Runnable
- ä½¿ç”¨ `pipe()` ä¸²è”å½¢æˆå¤„ç†é“¾
- æ•°æ®è‡ªåŠ¨åœ¨ Runnable ä¹‹é—´æµè½¬
- æ¯ä¸ª Runnable å¯ä»¥ç‹¬ç«‹æµ‹è¯•

---

### æ¡ˆä¾‹ 2ï¼šLambda å‡½æ•°åŒ…è£…

**æ–‡ä»¶**ï¼š[lambda-basic.ts](./lambda-basic.ts)

**åŠŸèƒ½**ï¼šå°†è‡ªå®šä¹‰å‡½æ•°åŒ…è£…ä¸º Runnable

**æ ¸å¿ƒä»£ç **ï¼š

```typescript
// æ•°æ®æ¸…æ´—
const sanitize = new RunnableLambda<string, string>((text) => {
  return text.trim().toLowerCase();
});

// åˆ†è¯
const tokenize = new RunnableLambda<string, string[]>((text) => {
  return text.split(/\s+/).filter(Boolean);
});

// è®¡æ•°
const count = new RunnableLambda<string[], number>((words) => {
  return words.length;
});

// ä¸²è”
const pipeline = sanitize.pipe(tokenize).pipe(count);

const result = await pipeline.invoke("  Hello World  ");
// ç»“æœ: 2
```

**è¿è¡Œç¤ºä¾‹**ï¼š

```bash
npm run runnable:lambda
```

**å­¦ä¹ è¦ç‚¹**ï¼š
- RunnableLambda å¯ä»¥åŒ…è£…ä»»æ„å‡½æ•°
- æ”¯æŒåŒæ­¥å’Œå¼‚æ­¥å‡½æ•°
- å¯ä»¥æŒ‡å®šè¾“å…¥è¾“å‡ºç±»å‹
- é€šè¿‡ pipe() ä¸å…¶ä»– Runnable ä¸²è”

---

### æ¡ˆä¾‹ 3ï¼šå¹¶è¡Œæ‰§è¡Œï¼ˆParallelï¼‰

**æ–‡ä»¶**ï¼š[parallel-basic.ts](./parallel-basic.ts)

**åŠŸèƒ½**ï¼šå¹¶è¡Œæ‰§è¡Œå¤šä¸ª Runnableï¼Œæå‡æ€§èƒ½

**æ ¸å¿ƒä»£ç **ï¼š

```typescript
const model = new ChatOpenAI({ temperature: 0 });

// åˆ›å»ºä¸‰ä¸ªåˆ†æé“¾
const summaryChain = PromptTemplate.fromTemplate("æ€»ç»“ï¼š{text}")
  .pipe(model).pipe(new StringOutputParser());

const sentimentChain = PromptTemplate.fromTemplate("æƒ…æ„Ÿï¼š{text}")
  .pipe(model).pipe(new StringOutputParser());

const keywordsChain = PromptTemplate.fromTemplate("å…³é”®è¯ï¼š{text}")
  .pipe(model).pipe(new StringOutputParser());

// å¹¶è¡Œæ‰§è¡Œ
const parallel = new RunnableParallel({
  summary: summaryChain,
  sentiment: sentimentChain,
  keywords: keywordsChain,
});

const result = await parallel.invoke({ text: "..." });
// ç»“æœ: { summary: "...", sentiment: "...", keywords: "..." }
```

**æ€§èƒ½å¯¹æ¯”**ï¼š

| æ‰§è¡Œæ–¹å¼ | è€—æ—¶ |
|---------|------|
| ä¸²è¡Œæ‰§è¡Œ | ~3000ms |
| å¹¶è¡Œæ‰§è¡Œ | ~1000ms |
| æ€§èƒ½æå‡ | **3å€** âš¡ |

**è¿è¡Œç¤ºä¾‹**ï¼š

```bash
npm run runnable:parallel
```

**å­¦ä¹ è¦ç‚¹**ï¼š
- RunnableParallel å¹¶è¡Œæ‰§è¡Œå¤šä¸ª Runnable
- æ˜¾è‘—æå‡ I/O å¯†é›†å‹ä»»åŠ¡çš„æ€§èƒ½
- ç»“æœæ±‡æ€»æˆä¸€ä¸ªå¯¹è±¡
- é€‚åˆæ‰‡å‡º/æ±‡èšæ¨¡å¼

---

### æ¡ˆä¾‹ 4ï¼šæ¡ä»¶åˆ†æ”¯ï¼ˆBranchï¼‰

**æ–‡ä»¶**ï¼š[branch-basic.ts](./branch-basic.ts)

**åŠŸèƒ½**ï¼šæ ¹æ®è¾“å…¥æ¡ä»¶é€‰æ‹©ä¸åŒçš„å¤„ç†è·¯å¾„

**æ ¸å¿ƒä»£ç **ï¼š

```typescript
const pathA = new RunnableLambda<string, string>((x) => x.toUpperCase());
const pathB = new RunnableLambda<string, string>((x) => x.toLowerCase());

// è·¯ç”±å™¨ï¼šæ ¹æ®æ¡ä»¶é€‰æ‹©è·¯å¾„
const router = new RunnableLambda<string, string>(async (input, config) => {
  const hasNumber = /\d/.test(input);

  if (hasNumber) {
    return pathA.invoke(input, config);
  } else {
    return pathB.invoke(input, config);
  }
});

await router.invoke("Hello123"); // "HELLO123" (è·¯å¾„A)
await router.invoke("Hello");    // "hello"    (è·¯å¾„B)
```

**è¿è¡Œç¤ºä¾‹**ï¼š

```bash
npm run runnable:branch
```

**å­¦ä¹ è¦ç‚¹**ï¼š
- ä½¿ç”¨ RunnableLambda å®ç°è·¯ç”±é€»è¾‘
- æ ¹æ®æ¡ä»¶åŠ¨æ€é€‰æ‹©æ‰§è¡Œè·¯å¾„
- æ¯ä¸ªè·¯å¾„éƒ½æ˜¯ç‹¬ç«‹çš„ Runnable
- ä¾¿äºæµ‹è¯•å’Œç»´æŠ¤

---

### æ¡ˆä¾‹ 5ï¼šæµå¼å¤„ç†ï¼ˆStreamï¼‰

**æ–‡ä»¶**ï¼š[stream-basic.ts](./stream-basic.ts)

**åŠŸèƒ½**ï¼šæµå¼è¾“å‡ºï¼Œå®æ—¶æ˜¾ç¤ºç”Ÿæˆå†…å®¹

**æ ¸å¿ƒä»£ç **ï¼š

```typescript
const model = new ChatOpenAI({
  streaming: true, // ğŸ”‘ å…³é”®ï¼šå¯ç”¨æµå¼
});

const chain = prompt.pipe(model).pipe(new StringOutputParser());

// æµå¼æ‰§è¡Œ
const stream = await chain.stream({ question: "ä»‹ç» Runnable" });

for await (const chunk of stream) {
  process.stdout.write(chunk); // æ‰“å­—æœºæ•ˆæœ
}
```

**è¿è¡Œç¤ºä¾‹**ï¼š

```bash
npm run runnable:stream
```

**å­¦ä¹ è¦ç‚¹**ï¼š
- å¯ç”¨ `streaming: true`
- ä½¿ç”¨ `stream()` æ–¹æ³•
- å®æ—¶è¾“å‡ºï¼Œé™ä½æ„ŸçŸ¥å»¶è¿Ÿ
- é€‚åˆé•¿æ–‡æœ¬ç”Ÿæˆåœºæ™¯

---

### æ¡ˆä¾‹ 6ï¼šé”™è¯¯å¤„ç†ä¸é‡è¯•

**æ–‡ä»¶**ï¼š[errors-basic.ts](./errors-basic.ts)

**åŠŸèƒ½**ï¼šé”™è¯¯å¤„ç†ã€å›é€€ç­–ç•¥ã€é‡è¯•æœºåˆ¶

**æ ¸å¿ƒä»£ç **ï¼š

```typescript
// ä¸»å¤„ç†é“¾
const primary = new RunnableLambda<string, string>((x) => {
  if (x.length < 5) throw new Error("è¾“å…¥å¤ªçŸ­");
  return x.toUpperCase();
});

// å›é€€å¤„ç†
const fallback = new RunnableLambda<string, string>((x) => {
  return `[fallback] ${x}`;
});

// å¸¦å›é€€çš„æ‰§è¡Œ
async function withFallback(input: string) {
  try {
    return await primary.invoke(input);
  } catch {
    return await fallback.invoke(input);
  }
}

await withFallback("hello");  // "HELLO"
await withFallback("hi");     // "[fallback] hi"
```

**é‡è¯•æœºåˆ¶**ï¼š

```typescript
async function retry<T>(fn: (x: T) => Promise<T>, x: T, times = 3) {
  let attempt = 0;

  while (attempt < times) {
    try {
      return await fn(x);
    } catch (e) {
      // æŒ‡æ•°é€€é¿
      await new Promise((r) => setTimeout(r, 2 ** attempt * 200));
      attempt++;
    }
  }

  throw new Error("é‡è¯•å¤±è´¥");
}
```

**è¿è¡Œç¤ºä¾‹**ï¼š

```bash
npm run runnable:errors
```

**å­¦ä¹ è¦ç‚¹**ï¼š
- é”™è¯¯ä¼šåœ¨ Runnable é“¾ä¸­ä¼ æ’­
- å¯ä»¥å®ç°å›é€€ç­–ç•¥
- æ”¯æŒé‡è¯•æœºåˆ¶ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
- é”™è¯¯å¤„ç†ä¸å½±å“ Runnable çš„ç»„åˆæ€§

---

## ğŸ¯ å®æˆ˜é¡¹ç›®

### é¡¹ç›® 1ï¼šå†…å®¹æ™ºèƒ½å¤„ç†æµæ°´çº¿

**æ–‡ä»¶**ï¼š[content-pipeline/processor.ts](./content-pipeline/processor.ts)

**åŠŸèƒ½**ï¼šå¯¹ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬è¿›è¡Œå…¨æ–¹ä½åˆ†æ

**å¤„ç†æµç¨‹**ï¼š

```
Input (ç”¨æˆ·æ–‡æœ¬)
  â†“
1. æ•°æ®æ¸…æ´—ï¼ˆå»å™ªã€æˆªæ–­ã€å®‰å…¨è¿‡æ»¤ï¼‰
  â†“
2. è¯­è¨€è¯†åˆ«ï¼ˆä¸­æ–‡/è‹±æ–‡/æ—¥æ–‡...ï¼‰
  â†“
3. ç¿»è¯‘ï¼ˆéä¸­æ–‡ç¿»è¯‘ä¸ºä¸­æ–‡ï¼‰
  â†“
4. æ‘˜è¦ç”Ÿæˆï¼ˆ3-5æ¡è¦ç‚¹ï¼‰
  â†“
5. å¹¶è¡Œåˆ†æ
   â”œâ”€ é£æ ¼åˆ†ç±»ï¼ˆæŠ€æœ¯/è¥é”€/æ–°é—»/éšç¬”ï¼‰
   â”œâ”€ æƒ…æ„Ÿåˆ†æï¼ˆæ­£é¢/ä¸­æ€§/è´Ÿé¢ï¼‰
   â””â”€ å…³é”®è¯æå–ï¼ˆ3-5ä¸ªå…³é”®è¯ï¼‰
  â†“
6. ç»“æ„åŒ–è¾“å‡ºï¼ˆJSONï¼‰
  â†“
Output { lang, text, summary, style, sentiment, keywords }
```

**æ ¸å¿ƒå®ç°**ï¼š

```typescript
// æ­¥éª¤ 1ï¼šæ•°æ®æ¸…æ´—
const sanitize = new RunnableLambda<{ text: string }, { text: string }>(
  ({ text }) => ({
    text: text.replace(/\s+/g, " ").trim().slice(0, 4000),
  })
);

// æ­¥éª¤ 2ï¼šè¯­è¨€è¯†åˆ«
const detectLang = PromptTemplate.fromTemplate(
  "åˆ¤æ–­è¯­è¨€ï¼š{text}\nåªè¿”å›ï¼šChinese/English/Japanese"
).pipe(model).pipe(parser);

// æ­¥éª¤ 3ï¼šç¿»è¯‘ï¼ˆå¦‚æœéœ€è¦ï¼‰
const translate = PromptTemplate.fromTemplate(
  "ç¿»è¯‘æˆä¸­æ–‡ï¼š{text}"
).pipe(model).pipe(parser);

// æ­¥éª¤ 4ï¼šæ‘˜è¦
const summarize = PromptTemplate.fromTemplate(
  "æ€»ç»“è¦ç‚¹ï¼ˆ3-5æ¡ï¼‰ï¼š{text}"
).pipe(model).pipe(parser);

// æ­¥éª¤ 5ï¼šå¹¶è¡Œåˆ†æ
const analyze = new RunnableParallel({
  style: PromptTemplate.fromTemplate("åˆ¤æ–­é£æ ¼ï¼š{text}").pipe(model).pipe(parser),
  sentiment: PromptTemplate.fromTemplate("åˆ¤æ–­æƒ…æ„Ÿï¼š{text}").pipe(model).pipe(parser),
  keywords: PromptTemplate.fromTemplate("æå–å…³é”®è¯ï¼š{text}").pipe(model).pipe(parser),
});

// ç»„åˆæˆå®Œæ•´æµæ°´çº¿
const contentPipeline = RunnableSequence.from([
  sanitize,
  // ... å…¶ä»–æ­¥éª¤
  analyze,
  formatOutput,
]);
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```typescript
const result = await contentPipeline.invoke({
  text: "LangChain unifies prompts, LLMs, retrievers...",
});

console.log(result);
// {
//   lang: "English",
//   text: "LangChain ç»Ÿä¸€äº† promptsã€LLMsã€retrievers...",
//   summary: "1. LangChain æ˜¯ç»Ÿä¸€æ¡†æ¶\n2. æä¾›å¯ç»„åˆç»„ä»¶\n3. ...",
//   style: "æŠ€æœ¯",
//   sentiment: "æ­£é¢",
//   keywords: ["LangChain", "æ¡†æ¶", "ç»„ä»¶"]
// }
```

**è¿è¡Œç¤ºä¾‹**ï¼š

```bash
npm run runnable:content-pipeline
```

**åº”ç”¨åœºæ™¯**ï¼š
- å†…å®¹å®¡æ ¸ç³»ç»Ÿ
- æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ
- å¤šè¯­è¨€å†…å®¹å¤„ç†
- æƒ…æ„Ÿåˆ†æå¹³å°

---

### é¡¹ç›® 2ï¼šRAG æ•°æ®å¤„ç†æµæ°´çº¿ï¼ˆETLï¼‰

**æ–‡ä»¶**ï¼š[rag-etl/processor.ts](./rag-etl/processor.ts)

**åŠŸèƒ½**ï¼šå°†åŸå§‹æ–‡æ¡£å¤„ç†æˆå‘é‡æ•°æ®åº“å¯ç”¨çš„æ ¼å¼

**å¤„ç†æµç¨‹**ï¼š

```
Input (æ–‡æ¡£è·¯å¾„/glob)
  â†“
1. åŠ è½½æ–‡ä»¶ï¼ˆMarkdown/PDF/TXTï¼‰
  â†“
2. æ–‡æ¡£åˆ†å—ï¼ˆRecursiveCharacterTextSplitterï¼‰
  â†“
3. è¿‡æ»¤çŸ­ç‰‡æ®µï¼ˆ< 50 å­—ç¬¦ï¼‰
  â†“
4. å»é‡ï¼ˆåŸºäºå†…å®¹ hashï¼‰
  â†“
5. å¹¶è¡ŒåµŒå…¥
   â”œâ”€ æ‰¹æ¬¡ 1 â†’ Embedding
   â”œâ”€ æ‰¹æ¬¡ 2 â†’ Embedding
   â””â”€ æ‰¹æ¬¡ 3 â†’ Embedding
  â†“
6. å†™å…¥å‘é‡åº“ï¼ˆChroma/Pinecone/Qdrantï¼‰
  â†“
7. ç”ŸæˆæŠ¥å‘Šï¼ˆå¤„ç†ç»Ÿè®¡ã€é”™è¯¯æ—¥å¿—ï¼‰
  â†“
Output { total, upserted, errors, duration }
```

**æ ¸å¿ƒå®ç°**ï¼š

```typescript
// æ­¥éª¤ 1ï¼šåŠ è½½æ–‡ä»¶
const loadFiles = new RunnableLambda<string, Document[]>(async (glob) => {
  const loader = new DirectoryLoader(glob);
  return await loader.load();
});

// æ­¥éª¤ 2ï¼šåˆ†å—
const splitDocs = new RunnableLambda<Document[], Document[]>(async (docs) => {
  const splitter = new RecursiveCharacterTextSplitter({
    chunkSize: 1000,
    chunkOverlap: 200,
  });
  return await splitter.splitDocuments(docs);
});

// æ­¥éª¤ 3ï¼šè¿‡æ»¤
const filterChunks = new RunnableLambda<Document[], Document[]>((docs) => {
  return docs.filter((doc) => doc.pageContent.trim().length >= 50);
});

// æ­¥éª¤ 4ï¼šå»é‡
const deduplicate = new RunnableLambda<Document[], Document[]>((docs) => {
  const seen = new Set<string>();
  return docs.filter((doc) => {
    const hash = createHash(doc.pageContent);
    if (seen.has(hash)) return false;
    seen.add(hash);
    return true;
  });
});

// æ­¥éª¤ 5ï¼šå¹¶è¡ŒåµŒå…¥
const embedBatch = new RunnableLambda<Document[], EmbeddedDoc[]>(
  async (docs) => {
    const embeddings = new OpenAIEmbeddings();
    // åˆ†æ‰¹å¤„ç†ï¼Œé¿å…è¶…å‡º API é™åˆ¶
    const batches = chunk(docs, 20);
    const results = await Promise.all(
      batches.map((batch) => embeddings.embedDocuments(batch))
    );
    return results.flat();
  }
);

// æ­¥éª¤ 6ï¼šå†™å…¥å‘é‡åº“
const upsertVectors = new RunnableLambda<EmbeddedDoc[], number>(
  async (docs) => {
    const vectorStore = new ChromaDB();
    await vectorStore.addDocuments(docs);
    return docs.length;
  }
);

// ç»„åˆæˆå®Œæ•´æµæ°´çº¿
const ragETL = RunnableSequence.from([
  loadFiles,
  splitDocs,
  filterChunks,
  deduplicate,
  embedBatch,
  upsertVectors,
  generateReport,
]);
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```typescript
const report = await ragETL.invoke("docs/**/*.md");

console.log(report);
// {
//   total: 150,
//   upserted: 142,
//   errors: 8,
//   duration: 45230,
//   stats: {
//     avgChunkSize: 856,
//     totalTokens: 121440,
//     estimatedCost: 0.012
//   }
// }
```

**è¿è¡Œç¤ºä¾‹**ï¼š

```bash
npm run runnable:rag-etl
```

**åº”ç”¨åœºæ™¯**ï¼š
- RAG ç³»ç»Ÿæ•°æ®é¢„å¤„ç†
- çŸ¥è¯†åº“æ„å»º
- æ–‡æ¡£å‘é‡åŒ–
- æ‰¹é‡æ•°æ®å¯¼å…¥

---

## â“ å¸¸è§é—®é¢˜

### Q1: Runnable å’Œæ™®é€šå‡½æ•°æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

**ç­”**ï¼š

| ç‰¹æ€§ | æ™®é€šå‡½æ•° | Runnable |
|------|---------|---------|
| ç»Ÿä¸€æ¥å£ | âŒ å„ä¸ç›¸åŒ | âœ… invoke/stream/batch |
| å¯ç»„åˆæ€§ | âŒ æ‰‹åŠ¨ç»„åˆ | âœ… pipe() è‡ªåŠ¨ä¸²è” |
| æµå¼æ”¯æŒ | âŒ éœ€è¦æ‰‹åŠ¨å®ç° | âœ… å†…ç½® stream() |
| æ‰¹å¤„ç† | âŒ éœ€è¦æ‰‹åŠ¨å®ç° | âœ… å†…ç½® batch() |
| Callback | âŒ éœ€è¦æ‰‹åŠ¨é›†æˆ | âœ… ç»Ÿä¸€ Callback æœºåˆ¶ |
| ç±»å‹å®‰å…¨ | âœ… TypeScript æ”¯æŒ | âœ… æ³›å‹å‚æ•° |

**ç¤ºä¾‹å¯¹æ¯”**ï¼š

```typescript
// âŒ æ™®é€šå‡½æ•°ï¼šéš¾ä»¥ç»„åˆ
async function process(input: string) {
  const cleaned = clean(input);
  const tokens = tokenize(cleaned);
  const count = countTokens(tokens);
  return count;
}

// âœ… Runnableï¼šæ˜“äºç»„åˆå’Œå¤ç”¨
const pipeline = clean.pipe(tokenize).pipe(count);
const result = await pipeline.invoke(input);

// åŒä¸€ä¸ªç»„ä»¶å¯ç”¨äºä¸åŒåœºæ™¯
const pipeline2 = clean.pipe(tokenize).pipe(analyze);
```

### Q2: ä»€ä¹ˆæ—¶å€™åº”è¯¥ä½¿ç”¨ RunnableParallelï¼Ÿ

**ç­”**ï¼š

**é€‚åˆå¹¶è¡Œ**ï¼ˆä½¿ç”¨ RunnableParallelï¼‰ï¼š
- âœ… I/O å¯†é›†å‹ä»»åŠ¡ï¼ˆAPI è°ƒç”¨ã€æ•°æ®åº“æŸ¥è¯¢ï¼‰
- âœ… ç‹¬ç«‹çš„è®¡ç®—ä»»åŠ¡
- âœ… å¤šä¸ª LLM è°ƒç”¨
- âœ… æ‰‡å‡º/æ±‡èšæ¨¡å¼

**ä¸é€‚åˆå¹¶è¡Œ**ï¼ˆä½¿ç”¨é¡ºåºæ‰§è¡Œï¼‰ï¼š
- âŒ æœ‰ä¾èµ–å…³ç³»çš„ä»»åŠ¡
- âŒ éœ€è¦ä¸²è¡Œæ‰§è¡Œçš„é€»è¾‘
- âŒ å…±äº«å¯å˜çŠ¶æ€çš„ä»»åŠ¡

**æ€§èƒ½å¯¹æ¯”**ï¼š

```typescript
// åœºæ™¯ï¼š3ä¸ªç‹¬ç«‹çš„ LLM è°ƒç”¨ï¼Œæ¯ä¸ªè€—æ—¶ 1 ç§’

// ä¸²è¡Œï¼š3 ç§’
const r1 = await task1.invoke(input);
const r2 = await task2.invoke(input);
const r3 = await task3.invoke(input);

// å¹¶è¡Œï¼š1 ç§’ âš¡
const parallel = new RunnableParallel({ r1: task1, r2: task2, r3: task3 });
const result = await parallel.invoke(input);
```

### Q3: å¦‚ä½•è°ƒè¯•å¤æ‚çš„ Runnable é“¾è·¯ï¼Ÿ

**ç­”**ï¼š

1. **é€æ­¥æµ‹è¯•**ï¼š

```typescript
// æµ‹è¯•æ¯ä¸ªç¯èŠ‚
const step1Result = await step1.invoke(input);
console.log("Step 1:", step1Result);

const step2Result = await step2.invoke(step1Result);
console.log("Step 2:", step2Result);

// ç„¶åæµ‹è¯•å®Œæ•´é“¾è·¯
const fullResult = await step1.pipe(step2).invoke(input);
```

2. **æ·»åŠ æ—¥å¿— Lambda**ï¼š

```typescript
const logLambda = new RunnableLambda((x) => {
  console.log("ä¸­é—´ç»“æœï¼š", x);
  return x; // åŸæ ·è¿”å›
});

const chain = step1.pipe(logLambda).pipe(step2);
```

3. **ä½¿ç”¨ Callback**ï¼š

```typescript
class DebugHandler extends BaseCallbackHandler {
  async handleChainStart(chain, inputs) {
    console.log(`[${chain.name}] è¾“å…¥:`, inputs);
  }

  async handleChainEnd(outputs) {
    console.log("è¾“å‡º:", outputs);
  }
}

await chain.invoke(input, {
  callbacks: [new DebugHandler()],
});
```

### Q4: Runnable çš„æ€§èƒ½å¼€é”€å¤§å—ï¼Ÿ

**ç­”**ï¼š

å¼€é”€å¾ˆå°ï¼Œå› ä¸ºï¼š

1. **è½»é‡æŠ½è±¡**ï¼šRunnable åªæ˜¯æ¥å£å±‚ï¼Œä¸å½±å“æ ¸å¿ƒé€»è¾‘
2. **é›¶æ‹·è´**ï¼šæ•°æ®åœ¨ Runnable ä¹‹é—´ä¼ é€’æ—¶ä¸ä¼šå¤åˆ¶
3. **æƒ°æ€§æ‰§è¡Œ**ï¼šåªåœ¨è°ƒç”¨ invoke/stream/batch æ—¶æ‰æ‰§è¡Œ

**æ€§èƒ½å¯¹æ¯”**ï¼š

```typescript
// æµ‹è¯•ï¼š1000 æ¬¡è°ƒç”¨

// æ™®é€šå‡½æ•°ï¼š1234ms
for (let i = 0; i < 1000; i++) {
  const result = await plainFunction(input);
}

// Runnableï¼š1256msï¼ˆå¼€é”€ < 2%ï¼‰
for (let i = 0; i < 1000; i++) {
  const result = await runnable.invoke(input);
}
```

**ä¼˜åŒ–å»ºè®®**ï¼š
- âœ… å¤ç”¨ Runnable å®ä¾‹ï¼ˆä¸è¦æ¯æ¬¡åˆ›å»ºæ–°çš„ï¼‰
- âœ… ä½¿ç”¨ batch() æ‰¹é‡å¤„ç†
- âœ… åˆç†ä½¿ç”¨å¹¶è¡Œï¼ˆRunnableParallelï¼‰
- âŒ é¿å…è¿‡åº¦åµŒå¥—ï¼ˆ> 10 å±‚ï¼‰

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. ç»„åˆåŸåˆ™

#### å•ä¸€èŒè´£

æ¯ä¸ª Runnable åªåšä¸€ä»¶äº‹ï¼š

```typescript
// âŒ ä¸æ¨èï¼šèŒè´£æ··æ‚
const processAll = new RunnableLambda(async (input) => {
  const cleaned = clean(input);
  const tokens = tokenize(cleaned);
  const analyzed = analyze(tokens);
  const formatted = format(analyzed);
  return formatted;
});

// âœ… æ¨èï¼šèŒè´£åˆ†ç¦»
const clean = new RunnableLambda((x) => ...);
const tokenize = new RunnableLambda((x) => ...);
const analyze = new RunnableLambda((x) => ...);
const format = new RunnableLambda((x) => ...);

const pipeline = clean.pipe(tokenize).pipe(analyze).pipe(format);
```

#### å¯å¤ç”¨æ€§

æŠ½å–é€šç”¨ç»„ä»¶ï¼š

```typescript
// é€šç”¨ç»„ä»¶åº“
const components = {
  clean: new RunnableLambda((x: string) => x.trim()),
  tokenize: new RunnableLambda((x: string) => x.split(/\s+/)),
  count: new RunnableLambda((x: any[]) => x.length),
};

// åœºæ™¯ 1ï¼šè®¡æ•°
const countPipeline = components.clean
  .pipe(components.tokenize)
  .pipe(components.count);

// åœºæ™¯ 2ï¼šåˆ†æ
const analyzePipeline = components.clean
  .pipe(components.tokenize)
  .pipe(analyzeTokens);
```

### 2. ç±»å‹å®‰å…¨

ä½¿ç”¨ TypeScript æ³›å‹ç¡®ä¿ç±»å‹å®‰å…¨ï¼š

```typescript
// æ˜ç¡®è¾“å…¥è¾“å‡ºç±»å‹
const process = new RunnableLambda<
  { text: string },           // è¾“å…¥ç±»å‹
  { words: string[]; count: number }  // è¾“å‡ºç±»å‹
>((input) => {
  const words = input.text.split(/\s+/);
  return { words, count: words.length };
});

// TypeScript ä¼šæ£€æŸ¥ç±»å‹
const result = await process.invoke({ text: "hello" });
// result: { words: string[]; count: number }

// âŒ ç¼–è¯‘é”™è¯¯
await process.invoke({ content: "hello" });
```

### 3. é”™è¯¯å¤„ç†ç­–ç•¥

#### ç­–ç•¥ 1ï¼šåœ¨ Lambda å†…éƒ¨å¤„ç†

```typescript
const safeParse = new RunnableLambda<string, number | null>((x) => {
  try {
    const num = parseFloat(x);
    return isNaN(num) ? null : num;
  } catch {
    return null;
  }
});
```

#### ç­–ç•¥ 2ï¼šåœ¨è°ƒç”¨æ–¹å¤„ç†

```typescript
try {
  const result = await chain.invoke(input);
} catch (error) {
  if (error instanceof ValidationError) {
    // å¤„ç†éªŒè¯é”™è¯¯
  } else {
    // å¤„ç†å…¶ä»–é”™è¯¯
  }
}
```

#### ç­–ç•¥ 3ï¼šå›é€€ç­–ç•¥

```typescript
async function withFallback<T>(
  primary: Runnable<T, any>,
  fallback: Runnable<T, any>,
  input: T
) {
  try {
    return await primary.invoke(input);
  } catch {
    return await fallback.invoke(input);
  }
}
```

### 4. æ€§èƒ½ä¼˜åŒ–

#### ä½¿ç”¨æ‰¹å¤„ç†

```typescript
// âŒ ä½æ•ˆï¼šé€ä¸ªå¤„ç†
for (const input of inputs) {
  await runnable.invoke(input);
}

// âœ… é«˜æ•ˆï¼šæ‰¹é‡å¤„ç†
await runnable.batch(inputs);
```

#### åˆç†ä½¿ç”¨å¹¶è¡Œ

```typescript
// åœºæ™¯ï¼š3ä¸ªç‹¬ç«‹çš„ LLM è°ƒç”¨

// âŒ ä¸²è¡Œï¼š~3ç§’
const a = await task1.invoke(input);
const b = await task2.invoke(input);
const c = await task3.invoke(input);

// âœ… å¹¶è¡Œï¼š~1ç§’
const parallel = new RunnableParallel({ a: task1, b: task2, c: task3 });
const result = await parallel.invoke(input);
```

#### ç¼“å­˜æ˜‚è´µæ“ä½œ

```typescript
const cache = new Map<string, any>();

const cachedRunnable = new RunnableLambda(async (input) => {
  const key = JSON.stringify(input);

  if (cache.has(key)) {
    return cache.get(key);
  }

  const result = await expensiveOperation(input);
  cache.set(key, result);
  return result;
});
```

### 5. æµ‹è¯•ç­–ç•¥

#### å•å…ƒæµ‹è¯•

```typescript
describe("Clean Lambda", () => {
  it("should trim whitespace", async () => {
    const result = await cleanLambda.invoke("  hello  ");
    expect(result).toBe("hello");
  });

  it("should handle empty input", async () => {
    const result = await cleanLambda.invoke("");
    expect(result).toBe("");
  });
});
```

#### é›†æˆæµ‹è¯•

```typescript
describe("Full Pipeline", () => {
  it("should process end-to-end", async () => {
    const result = await pipeline.invoke({
      text: "sample input",
    });

    expect(result).toHaveProperty("summary");
    expect(result).toHaveProperty("keywords");
  });
});
```

#### Mock LLM

```typescript
class MockLLM extends BaseChatModel {
  async _generate(messages: BaseMessage[]) {
    return {
      generations: [{
        text: "mocked response",
        message: new AIMessage("mocked response"),
      }],
    };
  }
}

const testChain = prompt.pipe(new MockLLM()).pipe(parser);
```

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- [LangChain.js Runnable æ–‡æ¡£](https://js.langchain.com/docs/modules/chains/)
- [LCEL (LangChain Expression Language)](https://js.langchain.com/docs/expression_language/)
- [TypeScript å®˜æ–¹æ–‡æ¡£](https://www.typescriptlang.org/docs/)

### å»¶ä¼¸é˜…è¯»

- [å‡½æ•°å¼ç¼–ç¨‹](https://github.com/getify/Functional-Light-JS)
- [å“åº”å¼ç¼–ç¨‹](https://rxjs.dev/)
- [ç®¡é“æ¨¡å¼](https://en.wikipedia.org/wiki/Pipeline_(software))

---

## ğŸ¯ æœ¬ç« å°ç»“

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å·²ç»æŒæ¡ï¼š

âœ… **æ ¸å¿ƒæ¦‚å¿µ**
- Runnable çš„å®šä¹‰å’Œæ ¸å¿ƒæ–¹æ³•
- å¸¸ç”¨å®ç°ï¼ˆLambdaã€Sequenceã€Parallelï¼‰
- ç¼–æ’æ¨¡å¼ï¼ˆé¡ºåºã€åˆ†æ”¯ã€æ‰‡å‡º/æ±‡èšï¼‰

âœ… **å®è·µæŠ€èƒ½**
- ä½¿ç”¨ pipe() ä¸²è” Runnable
- ä½¿ç”¨ RunnableLambda åŒ…è£…è‡ªå®šä¹‰é€»è¾‘
- ä½¿ç”¨ RunnableParallel æå‡æ€§èƒ½
- å®ç°é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

âœ… **å®æˆ˜é¡¹ç›®**
- å†…å®¹æ™ºèƒ½å¤„ç†æµæ°´çº¿
- RAG æ•°æ®å¤„ç†æµæ°´çº¿

âœ… **æœ€ä½³å®è·µ**
- å•ä¸€èŒè´£å’Œå¯å¤ç”¨æ€§
- ç±»å‹å®‰å…¨å’Œé”™è¯¯å¤„ç†
- æ€§èƒ½ä¼˜åŒ–å’Œæµ‹è¯•ç­–ç•¥

---

## ğŸš€ ä¸‹ä¸€æ­¥

åœ¨ä¸‹ä¸€ç« ã€ŠLangGraph ä¸çŠ¶æ€æœºç¼–æ’ã€‹ä¸­ï¼Œæˆ‘ä»¬å°†ï¼š

- å­¦ä¹ æœ‰çŠ¶æ€çš„å·¥ä½œæµç¼–æ’
- æ„å»ºå¤æ‚çš„ Agent ç³»ç»Ÿ
- å®ç°å¾ªç¯ã€æ¡ä»¶ã€å­å›¾ç­‰é«˜çº§æ¨¡å¼
- åœ¨ä¼ä¸šåœºæ™¯ä¸­è½åœ°å¯é çš„ AI åº”ç”¨

---

**ç¥å­¦ä¹ æ„‰å¿«ï¼å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿æ Issue è®¨è®ºã€‚** ğŸ‰
